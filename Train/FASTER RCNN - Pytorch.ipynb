{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import pandas as pd \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.engine import train_one_epoch, evaluate\n",
    "from python import utils\n",
    "import python.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annot(path):\n",
    "    data = {}\n",
    "    for i,e in enumerate(os.listdir(path)):\n",
    "        data_bach = pd.read_csv(os.path.join(path,e))\n",
    "        data_bach = data_bach.values[0]\n",
    "        x1 = int((data_bach[0].split(\" \")[0]).split(\".\")[0])\n",
    "        y1 = int((data_bach[0].split(\" \")[1]).split(\".\")[0])\n",
    "        x2 = int((data_bach[0].split(\" \")[2]).split(\".\")[0])\n",
    "        y2 = int((data_bach[0].split(\" \")[3]).split(\".\")[0])\n",
    "        data[e] = [x1,y1,x2,y2]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = parse_one_annot(\"Label\")\n",
    "#a['0.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, image, label, transforms=None):\n",
    "        self.image = image\n",
    "        self.transforms = transforms\n",
    "        self.imgs = sorted(os.listdir(image))\n",
    "        self.label =  parse_one_annot(label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            # load images and bounding boxes\n",
    "        img_path = os.path.join(self.image, self.imgs[idx])\n",
    "        img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "        box_list = self.label[self.imgs[idx].split(\".\")[0]+\".csv\"]\n",
    "        box_list = np.expand_dims(box_list, axis=0)\n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "            # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
    "            # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        #target[\"image_id\"] = image_id\n",
    "        #target[\"area\"] = area\n",
    "        #target[\"iscrowd\"] = iscrowd\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 500, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(\"Image\",\"Label\")\n",
    "dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "        # load an object detection model pre-trained on COCO\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)# get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "        # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372\n",
      "843\n",
      "We have: 8431 examples, 3372 are training and 843 testing\n"
     ]
    }
   ],
   "source": [
    "# use our dataset and defined transformationsdataset\n",
    "dataset = Dataset(\"Image\",\"Label\",get_transform(train=True))\n",
    "dataset_test = Dataset(\"Image\",\"Label\",get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "a = int(len(dataset)*4/10)\n",
    "print(a)\n",
    "b =int(len(dataset)/2 - a)\n",
    "print(b)\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:a])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-b:])                       \n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,num_workers=0,collate_fn=utils.collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=0,collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 594, 386])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - raccoon and not racoon\n",
    "num_classes = 2\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epoch\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python38\\lib\\site-packages\\torchvision\\ops\\boxes.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  keep = keep.nonzero().squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/3372]  eta: 1:22:47  lr: 0.000010  loss: 0.7551 (0.7551)  loss_classifier: 0.6836 (0.6836)  loss_box_reg: 0.0164 (0.0164)  loss_objectness: 0.0386 (0.0386)  loss_rpn_box_reg: 0.0166 (0.0166)  time: 1.4731  data: 0.0110  max mem: 1316\n",
      "Epoch: [0]  [  10/3372]  eta: 0:28:54  lr: 0.000060  loss: 0.7598 (0.7691)  loss_classifier: 0.6285 (0.6105)  loss_box_reg: 0.0903 (0.0817)  loss_objectness: 0.0149 (0.0639)  loss_rpn_box_reg: 0.0144 (0.0130)  time: 0.5159  data: 0.0051  max mem: 1615\n",
      "Epoch: [0]  [  20/3372]  eta: 0:26:16  lr: 0.000110  loss: 0.5504 (0.5887)  loss_classifier: 0.4164 (0.4447)  loss_box_reg: 0.0903 (0.0791)  loss_objectness: 0.0101 (0.0504)  loss_rpn_box_reg: 0.0105 (0.0145)  time: 0.4203  data: 0.0049  max mem: 1615\n",
      "Epoch: [0]  [  30/3372]  eta: 0:25:21  lr: 0.000160  loss: 0.3111 (0.4905)  loss_classifier: 0.1628 (0.3437)  loss_box_reg: 0.0921 (0.0837)  loss_objectness: 0.0101 (0.0485)  loss_rpn_box_reg: 0.0116 (0.0145)  time: 0.4221  data: 0.0075  max mem: 1631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f73d117630ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# update the learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# evaluate on the test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Acer\\Documents\\Git\\MatD3mons\\Multi_Face_Detector\\Train\\python\\engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\python38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# let's train it for 10 epochs\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch,print_freq=10)# update the learning rate\n",
    "    lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import time\n",
    "\n",
    "def get_model(num_classes):\n",
    "    # load an object detection model pre-trained on COCO\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)# get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "    return model\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "loaded_model = get_model(num_classes = 2)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_model.to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Image/46.jpg\")\n",
    "img = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "img = torch.tensor(img.transpose(2,1,0)).cuda()\n",
    "\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = time.time()\n",
    "    prediction = loaded_model([img])\n",
    "    b = time.time()\n",
    "    print(b-a)\n",
    "    \n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),decimals= 4)\n",
    "    cv2.rectangle(image, (int(boxes[1]), int(boxes[0])), (int(boxes[3]), int(boxes[2])), (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    break\n",
    "         \n",
    "plt.figure()        \n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
